---
title: "COVID-19 Morbidity and Seasonal Trends"
author: "Charles Fraley"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(forecast)
library(mgcv)
library(reshape)
library(stringi)
library(stringr)
library(knitr)
library(lubridate)
```

# Goal of Analysis

I'll be evaluating if there's a latitude influenced seasonal aspect to COVID mortality rates. This question is influenced by the knowledge that weather and climate has an influence on respiratory illness. If COVID deaths are largely related to respiratory distress, there may be a notable trend.

# Data
<!-- Was the source and a short description of the data provided? -->
## Intake and Source
I'll be using the [time series COVID-19 Data](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) from the Center for Systems Science and Engineering at Johns Hopkins.
```{r echo=T}
url_in <- "https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/"
time_path <- "csse_covid_19_time_series/time_series_covid19_"
time_filenames <- c(
    "confirmed_US.csv",
    #"confirmed_global.csv",
    #"deaths_global.csv",
    "deaths_US.csv"
)
for (branch_url in time_filenames) {
  time_data <- read.csv(
    url(
      paste(url_in,time_path,branch_url,sep="")
      )
    )
  assign(
    substring(branch_url,1,nchar(branch_url)-4),
    time_data
    )
}
```
# Demonstration of Method

I will be demonstrating my analysis using a single data entry:
```{r}
print(deaths_US$Combined_Key[1])
```

A new data frame for each row is made using each row from the confirmed and death spreadsheets. I use dates from either file's column headers. As dates come in the form of `Xmm-dd-yy` format, there is some transformation required to get a date object. We get the mortality ratio from $deaths/confirmed$. We remove any measurement of mortality ratio that is undefined or 0 as these can be considered an issue of measurement from early in the pandemic.
```{r echo=T}
working_df <- data.frame(
  date = colnames(deaths_US[-(1:12)]),
  confirmed=as.numeric(
      t(confirmed_US[1,])[-(1:11)]
     ),
  dead=as.numeric(t(deaths_US[1,])[-(1:12)])
)
working_df$date <- mdy(substring(working_df$date,2))
working_df <- mutate(working_df,ratio=dead/confirmed)
working_df <- mutate(working_df,datenum=as.numeric(date-mdy("12-31-2019")))
working_df <- mutate(working_df,
                     no_year=yday(date)
)
working_df <- na.omit(working_df)
# is.finite(working_df$ratio) & working_df$ratio!=0

```


```{r eval=T}
full_demo <- ggplot(working_df,aes(x=date,y=ratio))+geom_point(alpha=.3)+labs(x="Date",y="Ratio (Deaths/Confirmed Cases)")
suppressWarnings(full_demo)
```

I'll be trying to fit this data to the below formula.
$y=C_{periodic\ amplitude}*sin(\frac{2\pi}{1yr} t+C_{full\ year\ offset})-C_{trend}*t+C_{Intercept\ offset}$

I considered 2 approaches to this question:
1. Fit all data to one time axis with one fit.
2. Separate time data by year and create 3 different fits per year. 
3. Combine all data into one "combined year". As the time axis, use only the number of days since January 1st of that year.

## 1. Fit all data to one time axis with one fit
This would be the most intuitive way to handle it, handling all data as a single trend that can be considered.
<!-- TODO figure out what's with this -->
From our working dataframe assign a fit:
```{r eval=T}
full_model <- nls(
  ratio ~ a*sin((2*pi*datenum+b)/365)-c*datenum+d, 
  data=working_df,
  start=list(
    a=.001,
    b=-30,
    c=.001,
    d=.012
    )
  )
print(summary(full_model))
```
```{r}

fit <- predict(
  full_model,
  data=working_df$datenum, 
  interval='confidence'
  )
working_df$fit <- fit
print(summary(fit))
full_demo+geom_line(aes(date,working_df$fit),color="blue")
```

## 2. Exploration of Multiple Separate Year Evaluation
To avoid trying to model larger trends in the pandemic, we can take each year as a separate thing to model and use a more basic linear trend to mitigate that effect.

1. Separate year as own variable
```{r}
working_df <- mutate(working_df, year=year(date))
```
2. Similar handling except run 3 times. Separating model by year.
```{r}
model2020 <- nls(
  ratio ~ a*sin((2*pi*no_year+b)/365)-c*no_year+d, 
  data=filter(working_df,year==2020),
  start=list(
    a=.001,
    b=-30,
    c=.001,
    d=.012
    )
  )
print(summary(model2020))
model2021 <- nls(
  ratio ~ a*sin((2*pi*no_year+b)/365)-c*no_year+d, 
  data=filter(working_df,year==2021),
  start=list(
    a=.001,
    b=-30,
    c=.001,
    d=.012
    )
  )
print(summary(model2021))
model2022 <- nls(
  ratio ~ a*sin((2*pi*no_year+b)/365)-c*no_year+d, 
  data=filter(working_df,year==2022),
  start=list(
    a=.001,
    b=-30,
    c=.001,
    d=.012
    )
  )
print(summary(model2022))
```

```{r}
working_df$split_fit <-  unlist(
  c(
    predict(
      model2020,
      data=working_df$date, 
      interval='confidence'
    ),
    predict(
      model2021,
      data=working_df$date, 
      interval='confidence'
    ),
    predict(
      model2022,
      data=working_df$date, 
      interval='confidence'
    )
  )
)

split_demo <- ggplot(working_df,aes(x=date,y=ratio))+geom_point()

split_demo <- split_demo+
  geom_line(aes(date,working_df$split_fit),color="red")
split_demo
```

I did not use this in final analysis as the split is artificial and arbitrary.

## 3. Combined Year

I take every data point as a part of a single year. The independent variable is only the number of days since the start of the year.
```{r}
demoplot <- ggplot(working_df,aes(x=no_year,y=ratio))+geom_point(alpha=.1)
```
```{r eval=T}
working_df <- na.omit(working_df)
demo_model <- nls(
  ratio ~ a*sin((2*pi*no_year+b)/365)-c*no_year+d, 
  data=working_df,
  start=list(
    a=.001,
    b=-30,
    c=.001,
    d=.012
    )
  )
print(summary(demo_model))

working_df$fit <-  predict(demo_model,data=working_df$no_year, interval='confidence')
demoplot <- demoplot+geom_line(aes(no_year,working_df$fit),color="green")
# demoplot <- demoplot+geom_ribbon(aes(ymin=lwr,ymax=upr), alpha=0.3)
```
```{r}
demoplot
```

# Analysis
Map each area of examination to their latitude

For measuring across multiple locations I'll be using the all as one year analysis. Additionally I will be disregarding the ratio values of 0 at the beginning of the pandemic as these are clearly an issue of how data was collected when COVID emerged. From each county, I need the value for periodic amplitude for the model and the latitude.

## Collective Curve

```{r}
df_rows <- nrow(confirmed_US)
singtime <- data.frame(
  uid=confirmed_US$UID,
  combined_key=confirmed_US$Combined_Key,
  latitude=confirmed_US$Lat,
  amp=rep(NA,df_rows),
  amp_err=rep(NA,df_rows),
  off=rep(NA,df_rows),
  off_err=rep(NA,df_rows)
  )
working_df <- data.frame(
    datenum = as.numeric(
      mdy(substring(colnames(deaths_US[-(1:12)]),2))-
        mdy("12-31-2019"))
)

```

```{r}
for (rownum in 1:nrow(singtime)) {
  if (grepl("Out of",confirmed_US$Admin2[rownum]) || grepl("Unassigned",confirmed_US$Admin2[rownum]) ){
    next
  }
  # print(rownum)
  working_df$ratio <- 
      as.numeric(t(deaths_US[rownum,])[-(1:12)])/
      as.numeric(t(confirmed_US[rownum,])[-(1:11)])
  skip <- F
  tryCatch(
    work_fit <-nls(
      ratio ~ a*sin((2*pi*datenum+b)/365)-c*datenum+d, 
      data=working_df,
      start=list(
        a=.001,
        b=-30,
        c=.001,
        d=.012
        )
    ),
    error = function(e) {
      skip <- T
    }
  )
  if(skip) {
    next
  }
  mod_sum <-summary(work_fit)
  singtime$amp[rownum] <- coef(work_fit)['a']
  singtime$amp_err[rownum] <- mod_sum$coefficients[,2]['a']
  singtime$off[rownum] <- coef(work_fit)['c']%%365
  singtime$off_err[rownum] <- mod_sum$coefficients[,2]['c']
  # na.omit(working_df)
}

```
```{r}
sing_lat_plot <- ggplot(
  singtime,
  mapping =aes(x=latitude,y=abs(amp)))+
  coord_cartesian(xlim=c(12,50),ylim=c(0,.01))+
  geom_point(alpha=.05)
# +geom_errorbar(mapping=aes(x=Latitude,))
suppressWarnings(sing_lat_plot)
```
```{r}
ggplot(
     singtime,
     mapping =aes(x=latitude,y=off))+
     geom_point(alpha=.1)
```

## Combined Year

```{r}
allin1 <- data.frame(
  uid=confirmed_US$UID,
  combined_key=confirmed_US$Combined_Key,
  latitude=confirmed_US$Lat,
  amp=rep(NA,nrow(confirmed_US)),
  amp_err=rep(NA,nrow(confirmed_US)),
  off=rep(NA,nrow(confirmed_US)),
  off_err=rep(NA,nrow(confirmed_US))
)
working_df <- data.frame(
    ydays = yday(mdy(substring(colnames(deaths_US[-(1:12)]),2)))
)
```
```{r}
for (rownum in 1:nrow(allin1)) {
  if (grepl("Out of",confirmed_US$Admin2[rownum]) || grepl("Unassigned",confirmed_US$Admin2[rownum]) ){
    next
  }
  # print(rownum)
  working_df$ratio <- 
      as.numeric(t(deaths_US[rownum,])[-(1:12)])/
      as.numeric(t(confirmed_US[rownum,])[-(1:11)])
  skip <- F
  tryCatch(
    work_fit <-nls(
    ratio ~ a*sin((2*pi*(ydays+c))/365)+b, 
    working_df[
      is.finite(working_df$ratio) & working_df$ratio!=0,
    ],
    start=list(
        a=.001,
        b=.012,
        c=-30
      )
    ),
    error = function(e) {
      skip <- T
    }
  )
  if(skip) {
    next
  }
  mod_sum <-summary(work_fit)
  allin1$amp[rownum] <- coef(work_fit)['a']
  allin1$amp_err[rownum] <- mod_sum$coefficients[,2]['a']
  allin1$off[rownum] <- coef(work_fit)['c']%%365
  allin1$off_err[rownum] <- mod_sum$coefficients[,2]['c']
  # na.omit(working_df)
}
```
```{r eval=F}
allin1 <- na.omit(allin1)
allin1$amp[allin1$amp <0 & allin1$off >= 365/2 ] <- -1*allin1$amp
allin1$off[allin1$amp <0 & allin1$off >= 365/2 ] <- allin1$off-365/2
```
```{r}
allin1 <- mutate(allin1,amp_max=amp+amp_err) %>%mutate(amp_min=amp-amp_err)
```

No apparent correlation.
```{r}
all_lat_plot <- ggplot(
  allin1,
  mapping =aes(x=latitude,y=abs(amp)))+
  coord_cartesian(xlim=c(12,50),ylim=c(0,.01))+
  geom_point(alpha=.01)
# +geom_errorbar(mapping=aes(x=Latitude,))
suppressWarnings(all_lat_plot)
```
If there was a shared seasonal periodicity, there would be similarity across latitude of the offset of the period.
```{r}
ggplot(
     allin1,
     mapping =aes(x=latitude,y=off))+
     geom_point(alpha=.1)
```

### Correlation latitude of counties to their periodic amplitude
```{r}
all_lat_plot
```

# Conclusion
It doesn't appear there is a relation between periodic changes in mortality and latitude based on my model.
This is encouraged by the lack of correlation in the offset. 

## Methodological Considerations

US focus because going across country lines means even more variability. Special consideration would need to be given to vaccine availability and differences in national health care. This would be beyond the scope of this analysis.

### Assumptions

- Period of 1 year
- Skip past 0 deaths

# Further questions
Consider state and country analysis.
Better larger trend mitigation. Global averages/regional neighbor average.

## Bias and Mitigation

# TODO
- Fix the offset amplitude flip mutation
- offset %%365 or %%(365/2) comparison
- [Suppress warnings](https://stackoverflow.com/questions/13286531/how-to-suppress-warnings-when-plotting-with-ggplot)